name: scraper
on:
  push:
    branches:
      - master
  schedule:
    - cron:  '0 */15 * * *'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:

      - name: checkout repo content
        uses: actions/checkout@v2 # checkout the repository content to github runner

      - name: setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.7.7' # install the python version needed
          
      - name: install python packages
        run: |
          python -m pip install --upgrade pip
          python -m pip install --upgrade pip
          pip install -U pip setuptools
          pip install pendulum beautifulsoup4 requests
      - name: Script check
        uses: jannekem/run-python-script-action@v1
        with:
          script: |
            import requests
            from datetime import datetime
            import time
            now = datetime.now()
            def parseurl(url):
                gparse= []
                try:
                    response=requests.get(url)
                    if response.status_code==200:
                        r=response.json()
                        gee_id=r['id']
                        gee_title=r['title']
                        gee_type=r['gee:type']
                        gee_start=r['extent']['temporal']['interval'][0][0].split('T')[0]
                        if not r['extent']['temporal']['interval'][0][1]==None:
                            gee_end=r['extent']['temporal']['interval'][0][1].split('T')[0]
                        else:
                            gee_end=now.strftime('%Y-%m-%d')
                        gee_start_year=gee_start.split('-')[0]
                        gee_end_year=gee_end.split('-')[0]
                        gee_provider=r['providers'][0]['name']
                        gee_tags=r['keywords']
                        print([gee_id,gee_provider,gee_title,gee_start,gee_end,gee_start_year,gee_end_year,gee_type,', '.join(gee_tags)])
                except Exception as e:
                    print(e)
            def ee_catalog():
                obj = requests.get('https://earthengine-stac.storage.googleapis.com/catalog/catalog.json').json()
                try:
                    for assets in obj['links']:
                        if assets['rel']=='child':
                            print(assets['href'])
                            parseurl(assets['href'])
                except Exception as e:
                    print(e)
            ee_catalog()
      - name: execute py script # run sj-gobierno.py to get the latest data
        run: python ee_data_stac.py
      - name: file_check
        run: ls -l -a
      - name: commit files
        run: |
          git add -A
          git commit -m "update data" -a
      - name: push changes
        uses: ad-m/github-push-action@v0.6.0
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: main
